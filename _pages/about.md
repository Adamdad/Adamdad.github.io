---
permalink: /
title: "Xingyi Yang"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<style type="text/css">
  body{
  font-size: 14pt;
}
</style>

 ğŸš€ğŸ‘¨â€ğŸ’»ğŸ¥ğŸ’¡Hi, my name is Xingyi Yang (Adam)ğŸ’¡ğŸ¥ğŸ‘¨â€ğŸ’»ğŸš€.

I will be joining The Hong Kong Polytechnic University (PolyU) in 2025 Fall as a tenure-track Assistant Professor in the [Department of Data Science and Artificial Intelligence (DSAI)](https://www.polyu.edu.hk/dsai/?sc_lang=en). I am also honored to have been selected as the prestigious **Presidential Young Scholars** at PolyU.

Currently, I am a final-year Ph.D. candidate at NUS, advised by Prof.Xinchao Wang. I also spent wonderful times as a visiting PhD at University of Oxford, advised by Prof.Philip Torr. 

<!-- I am grateful for the recognition my work has received, including a NeurIPS 2022 Best Paper Nomination, the 2023 National Award for Outstanding Self-financed Chinese Students Abroad, and a WAIC 2024 Youth Excellent Paper Nomination. -->

------

My research lies at the intersection of **generative AI** and **multi-modal learning**, with a strong emphasis on their computational **efficiency**. Our mission is to build intelligent systems that robustly understand, generate, and interact with physical worlds. We hope to achieve this with minimum cost, by tapping and repurposing the rich capabilities of large foundation models through modular, compositional, and post-training techniques.

------

### ğŸ’¥ Hiring! ğŸ’¥

I am looking for self-motivated Ph.D. students, postdocs, and research assistants for Spring/Fall 2026. If you are interested in working with me, feel free to reach out via email with your resume.


<!-- My current research interest lies in **Deep Model Reuse** and its Applications:
- **Deep Model Reuse**: Rather than trying to cook up a universal model in one grand kitchen experiment, my vision is to reuse pre-trained neural networks to do new things. By composing their expertise, editing their behaviour and enhancing their reliability, the goal is to craft models that become Jacks of all trades, or at least, one step closer to the dream of Artificial General Intelligence (AGI).
- **Compositionality & Modularity**: Building ML system is like playing a game of LEGO, where I piece together elements from various tasks, concepts, and logic, crafting cost-effective AI masterpieces.
- **Generative Models and 3D Vision**:  I'm super excited about generative models, especially diffusion-based ones. They have the power to create magic in 3D and even 4D worlds â€“ all, hopefully, with a side of solid theory.  -->

<!-- My work centers on generative models (especially diffusion-based), representation learning, trustworthy learning (emphasizing interpretability and robustness), and graph learning. -->
<!-- - Efficiency, that empowers the AI learn with minimum computation and data requirement.  -->
<!-- - Data Efficency. Focus on self-supervised & semi-supervised & weak-supervised learning or learning with synthesized data. -->

[CV](http://adamdad.github.io/files/CV_XingyiYang_202506.pdf)

I believe in [Slow Science](http://slow-science.org/)

